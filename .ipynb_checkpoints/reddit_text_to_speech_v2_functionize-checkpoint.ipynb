{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8d3f57d4-9fb2-4b9b-8422-93832129ea39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import sys\n",
    "sys.path.append('C:\\\\Users\\\\kevin\\\\Google Drive\\\\My Drive\\\\Github\\\\all-api-keys')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6d480a-5d81-4251-ac85-2881d1bd35aa",
   "metadata": {},
   "source": [
    "# Reddit API Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a4f98c72-7a6f-4d76-a15e-810836701875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the current directory\n",
    "original_directory = 'C:\\\\Users\\\\kevin\\\\Google Drive\\\\My Drive\\\\Github\\\\Repos\\\\reddit_text_to_speech'\n",
    "\n",
    "# Switch to the new directory\n",
    "new_directory = 'C:\\\\Users\\\\kevin\\\\Google Drive\\\\My Drive\\\\Github\\\\all-api-keys'\n",
    "os.chdir(new_directory)\n",
    "\n",
    "# Your code that operates in the new directory goes here\n",
    "import secret\n",
    "\n",
    "# Switch back to the original directory\n",
    "os.chdir(original_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ef6637ea-f666-4b0d-9512-b36ec94236b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id = secret.reddit_client_id,\n",
    "                     client_secret=secret.reddit_secret_key,\n",
    "                     user_agent=secret.reddit_app_name,\n",
    "                     username=secret.reddit_username,\n",
    "                     password=secret.reddit_password)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6874399e-6bd0-4aa4-ad24-7dc5e61e13b3",
   "metadata": {},
   "source": [
    "# Pull Comments from Reddit Subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "df55672a-670a-4ec3-a54d-9b644e55b03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Choose the subreddit\n",
    "# subreddit_name = \"askreddit\"\n",
    "\n",
    "# # Access the subreddit\n",
    "# subreddit = reddit.subreddit(subreddit_name)\n",
    "\n",
    "# # Of last 24 hours only.\n",
    "# top_posts = subreddit.top(time_filter='day', limit=10)\n",
    "# # Fetch the top 10 posts from all time\n",
    "# # top_posts = subreddit.top(limit=10)\n",
    "\n",
    "# # Initialize an empty list to store the data\n",
    "# data = []\n",
    "\n",
    "# # Iterate over the posts and comments\n",
    "# for post in top_posts:\n",
    "#     post_title = post.title\n",
    "#     post_url = post.url\n",
    "#     subreddit_name = post.subreddit.display_name\n",
    "\n",
    "#     post.comment_sort = 'top'  # Sort comments by top votes\n",
    "#     post.comments.replace_more(limit=0)  # Load all comments, remove 'more comments' links\n",
    "\n",
    "#     # top_comments = post.comments.list()[:10]\n",
    "#     # Can't just go for top comments, need to swerve the \"[removed]\" ones.\n",
    "#     # Initialize an empty list to hold the top comments\n",
    "#     top_comments = []\n",
    "    \n",
    "#     # Iterate through the list of comments\n",
    "#     for comment in post.comments.list():\n",
    "#         # Check if the comment has not been removed\n",
    "#         if not comment.body == \"[removed]\":\n",
    "#             # Add the comment to the list of top comments\n",
    "#             top_comments.append(comment)\n",
    "#         # Break the loop if we have collected 10 comments\n",
    "#         if len(top_comments) == 10:\n",
    "#             break\n",
    "\n",
    "#     for comment in top_comments:\n",
    "#         # Append each comment along with post and subreddit details to the data list\n",
    "#         data.append([subreddit_name, post_title, post_url, comment.body])\n",
    "\n",
    "# # Create a DataFrame\n",
    "# df = pd.DataFrame(data, columns=['Subreddit', 'Post Title', 'Post URL', 'Comment'])\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "916acaab-91f4-42e6-9543-684270e42e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_emojis(text):\n",
    "#     # Define a regular expression pattern for emojis\n",
    "#     emoji_pattern = re.compile(\"[\"\n",
    "#                                u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "#                                u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "#                                u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "#                                u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "#                                u\"\\U00002702-\\U000027B0\"\n",
    "#                                u\"\\U000024C2-\\U0001F251\" \n",
    "#                                \"]+\", flags=re.UNICODE)\n",
    "#     return emoji_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b5dd779d-e852-415c-931d-eb2e5ad87904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Apply remove_emojis function to all elements in the DataFrame\n",
    "# df = df.applymap(remove_emojis)\n",
    "\n",
    "# # This didnt work i saw an emoji:\n",
    "# # for column in df.columns:\n",
    "#     # df[column] = df[column].map(remove_emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c3c8559f-717c-4dc9-9189-c2346d793b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Now you can export the DataFrame\n",
    "# df.to_csv('reddit_data.csv', index=False, encoding='utf-16', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f18221-2cff-4224-815c-8d26b9b35cb8",
   "metadata": {},
   "source": [
    "# Function: Reddit to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b84e2fd5-ce42-4c31-89b1-0c9e684daf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reddit_to_df(subreddit_name=\"askreddit\", time_filter='day', n_posts=10):\n",
    "    # Choose the subreddit\n",
    "    # subreddit_name = \"askreddit\"\n",
    "    \n",
    "    # Access the subreddit\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "    \n",
    "    # Of last 24 hours only.\n",
    "    top_posts = subreddit.top(time_filter=time_filter, limit=n_posts)\n",
    "    \n",
    "    # Fetch the top 10 posts from all time\n",
    "    # top_posts = subreddit.top(limit=10)\n",
    "    \n",
    "    # Initialize an empty list to store the data\n",
    "    data = []\n",
    "    \n",
    "    # Iterate over the posts and comments\n",
    "    for post in top_posts:\n",
    "        post_title = post.title\n",
    "        post_url = post.url\n",
    "        subreddit_name = post.subreddit.display_name\n",
    "    \n",
    "        post.comment_sort = 'top'  # Sort comments by top votes\n",
    "        post.comments.replace_more(limit=0)  # Load all comments, remove 'more comments' links\n",
    "    \n",
    "        # top_comments = post.comments.list()[:10]\n",
    "        # Can't just go for top comments, need to swerve the \"[removed]\" ones.\n",
    "        # Initialize an empty list to hold the top comments\n",
    "        top_comments = []\n",
    "        \n",
    "        # Iterate through the list of comments\n",
    "        for comment in post.comments.list():\n",
    "            # Check if the comment has not been removed\n",
    "            if not (comment.body == \"[removed]\" or comment.body == \"[deleted]\"):\n",
    "                # Add the comment to the list of top comments\n",
    "                top_comments.append(comment)\n",
    "            # Break the loop if we have collected 10 comments\n",
    "            if len(top_comments) == n_posts:\n",
    "                break\n",
    "    \n",
    "        for comment in top_comments:\n",
    "            # Append each comment along with post and subreddit details to the data list\n",
    "            data.append([subreddit_name, post_title, post_url, comment.body])\n",
    "    \n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame(data, columns=['Subreddit', 'Post Title', 'Post URL', 'Comment'])\n",
    "\n",
    "    def remove_emojis(text):\n",
    "        # Define a regular expression pattern for emojis\n",
    "        emoji_pattern = re.compile(\"[\"\n",
    "                                   u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                                   u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                                   u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                                   u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                                   u\"\\U00002702-\\U000027B0\"\n",
    "                                   u\"\\U000024C2-\\U0001F251\" \n",
    "                                   \"]+\", flags=re.UNICODE)\n",
    "        return emoji_pattern.sub(r'', text)\n",
    "    # Remove emojis    \n",
    "    df = df.applymap(remove_emojis)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f1337291-1822-4103-98d9-8696dfe572e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_csv(df):\n",
    "    df.to_csv('reddit_data.csv', index=False, encoding='utf-16', sep='\\t')\n",
    "    return 'Complete!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9fde1d06-2989-46ad-b9b4-ccd649c9e521",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\AppData\\Local\\Temp\\ipykernel_21720\\1300757402.py:60: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(remove_emojis)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Post Title</th>\n",
       "      <th>Post URL</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AskReddit</td>\n",
       "      <td>People who have straight up rage quit a job, w...</td>\n",
       "      <td>https://www.reddit.com/r/AskReddit/comments/1a...</td>\n",
       "      <td>Many years ago while working in a manufacturin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AskReddit</td>\n",
       "      <td>People who have straight up rage quit a job, w...</td>\n",
       "      <td>https://www.reddit.com/r/AskReddit/comments/1a...</td>\n",
       "      <td>Not me, but a colleague once wrote a long stin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AskReddit</td>\n",
       "      <td>People who have straight up rage quit a job, w...</td>\n",
       "      <td>https://www.reddit.com/r/AskReddit/comments/1a...</td>\n",
       "      <td>This was 20 years ago.\\n\\n\\nMy fiancé had been...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AskReddit</td>\n",
       "      <td>People who have straight up rage quit a job, w...</td>\n",
       "      <td>https://www.reddit.com/r/AskReddit/comments/1a...</td>\n",
       "      <td>I never have, but my favorite example was when...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AskReddit</td>\n",
       "      <td>People who have straight up rage quit a job, w...</td>\n",
       "      <td>https://www.reddit.com/r/AskReddit/comments/1a...</td>\n",
       "      <td>At one office job, I quit after the first day ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>AskReddit</td>\n",
       "      <td>You are on a first date, and they tell you the...</td>\n",
       "      <td>https://www.reddit.com/r/AskReddit/comments/1a...</td>\n",
       "      <td>nobody mentioned CATS yet?\\n\\ncan't blame peop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>AskReddit</td>\n",
       "      <td>You are on a first date, and they tell you the...</td>\n",
       "      <td>https://www.reddit.com/r/AskReddit/comments/1a...</td>\n",
       "      <td>50 Shades</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>AskReddit</td>\n",
       "      <td>You are on a first date, and they tell you the...</td>\n",
       "      <td>https://www.reddit.com/r/AskReddit/comments/1a...</td>\n",
       "      <td>Lord of the ring theatrical. \\n\\n\\nYou go exte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>AskReddit</td>\n",
       "      <td>You are on a first date, and they tell you the...</td>\n",
       "      <td>https://www.reddit.com/r/AskReddit/comments/1a...</td>\n",
       "      <td>Spaceballs. Hear me out. I am walking to buy a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>AskReddit</td>\n",
       "      <td>You are on a first date, and they tell you the...</td>\n",
       "      <td>https://www.reddit.com/r/AskReddit/comments/1a...</td>\n",
       "      <td>Hot College Coeds 9. Terrible storyline, they ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Subreddit                                         Post Title  \\\n",
       "0   AskReddit  People who have straight up rage quit a job, w...   \n",
       "1   AskReddit  People who have straight up rage quit a job, w...   \n",
       "2   AskReddit  People who have straight up rage quit a job, w...   \n",
       "3   AskReddit  People who have straight up rage quit a job, w...   \n",
       "4   AskReddit  People who have straight up rage quit a job, w...   \n",
       "..        ...                                                ...   \n",
       "95  AskReddit  You are on a first date, and they tell you the...   \n",
       "96  AskReddit  You are on a first date, and they tell you the...   \n",
       "97  AskReddit  You are on a first date, and they tell you the...   \n",
       "98  AskReddit  You are on a first date, and they tell you the...   \n",
       "99  AskReddit  You are on a first date, and they tell you the...   \n",
       "\n",
       "                                             Post URL  \\\n",
       "0   https://www.reddit.com/r/AskReddit/comments/1a...   \n",
       "1   https://www.reddit.com/r/AskReddit/comments/1a...   \n",
       "2   https://www.reddit.com/r/AskReddit/comments/1a...   \n",
       "3   https://www.reddit.com/r/AskReddit/comments/1a...   \n",
       "4   https://www.reddit.com/r/AskReddit/comments/1a...   \n",
       "..                                                ...   \n",
       "95  https://www.reddit.com/r/AskReddit/comments/1a...   \n",
       "96  https://www.reddit.com/r/AskReddit/comments/1a...   \n",
       "97  https://www.reddit.com/r/AskReddit/comments/1a...   \n",
       "98  https://www.reddit.com/r/AskReddit/comments/1a...   \n",
       "99  https://www.reddit.com/r/AskReddit/comments/1a...   \n",
       "\n",
       "                                              Comment  \n",
       "0   Many years ago while working in a manufacturin...  \n",
       "1   Not me, but a colleague once wrote a long stin...  \n",
       "2   This was 20 years ago.\\n\\n\\nMy fiancé had been...  \n",
       "3   I never have, but my favorite example was when...  \n",
       "4   At one office job, I quit after the first day ...  \n",
       "..                                                ...  \n",
       "95  nobody mentioned CATS yet?\\n\\ncan't blame peop...  \n",
       "96                                          50 Shades  \n",
       "97  Lord of the ring theatrical. \\n\\n\\nYou go exte...  \n",
       "98  Spaceballs. Hear me out. I am walking to buy a...  \n",
       "99  Hot College Coeds 9. Terrible storyline, they ...  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = reddit_to_df(subreddit_name=\"askreddit\", time_filter='day', n_posts=10)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9b7fa691-2433-49da-9349-a651a30e74ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Complete!'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_csv(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92237ec-2136-4cc4-83a2-a92942b7cce0",
   "metadata": {},
   "source": [
    "# Use ElevenLabs API to text-to-speech your df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "62ace649-f88b-411e-8275-1704e88d4bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import elevenlabs\n",
    "elevenlabs.set_api_key(secret.eleven_labs_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5c703ab6-09ed-4abb-90d7-681c45b72b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\\\\\Users\\\\\\\\kevin\\\\\\\\Google Drive\\\\\\\\My Drive\\\\\\\\Github\\\\\\\\Repos\\\\\\\\reddit_text_to_speech\\\\\\\\elevenlabs_audio'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp3_file_path = r'C:\\Users\\kevin\\Google Drive\\My Drive\\Github\\Repos\\reddit_text_to_speech\\elevenlabs_audio'\n",
    "# Adding an extra '\\' to every '\\' found in the original path\n",
    "escaped_path = mp3_file_path.replace(\"\\\\\", \"\\\\\\\\\")\n",
    "download_directory = escaped_path\n",
    "download_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "46807b61-d010-4fac-a710-1516f9226ba1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pFZP5JQG7iQjIQuC4Bku\n",
      "Lily\n",
      "accent: british\n",
      "description: raspy\n",
      "age: middle aged\n",
      "gender: female\n",
      "use case: narration\n"
     ]
    }
   ],
   "source": [
    "# What voices are available?\n",
    "from elevenlabs.api import Voices\n",
    "voices = Voices.from_api()\n",
    "# print(voices[0])\n",
    "# Iterate through each voice object\n",
    "for voice in voices:\n",
    "    if voice.name == 'Lily':\n",
    "        print(voice.voice_id)\n",
    "        print(voice.name)\n",
    "        if voice.labels:  # Check if labels are not None or empty\n",
    "            for label, value in voice.labels.items():\n",
    "                print(f\"{label}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "970f90eb-659c-4c70-95cd-c29bce2b6ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Post Title</th>\n",
       "      <th>Post URL</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AskReddit</td>\n",
       "      <td>What is something that you believe every canna...</td>\n",
       "      <td>https://www.reddit.com/r/AskReddit/comments/1a...</td>\n",
       "      <td>It affects your memory, as well as your memory.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AskReddit</td>\n",
       "      <td>What is something that you believe every canna...</td>\n",
       "      <td>https://www.reddit.com/r/AskReddit/comments/1a...</td>\n",
       "      <td>It’s not for everyone. Some people truly do ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AskReddit</td>\n",
       "      <td>What is something that you believe every canna...</td>\n",
       "      <td>https://www.reddit.com/r/AskReddit/comments/1a...</td>\n",
       "      <td>Stay hydrated.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AskReddit</td>\n",
       "      <td>What is something that you believe every canna...</td>\n",
       "      <td>https://www.reddit.com/r/AskReddit/comments/1a...</td>\n",
       "      <td>If you have an underlying mental health disord...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AskReddit</td>\n",
       "      <td>What is something that you believe every canna...</td>\n",
       "      <td>https://www.reddit.com/r/AskReddit/comments/1a...</td>\n",
       "      <td>When deciding how many edibles…You can always ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AskReddit</td>\n",
       "      <td>What is something that you believe every canna...</td>\n",
       "      <td>https://www.reddit.com/r/AskReddit/comments/1a...</td>\n",
       "      <td>You smell like weed, you're just nose blind to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AskReddit</td>\n",
       "      <td>What is something that you believe every canna...</td>\n",
       "      <td>https://www.reddit.com/r/AskReddit/comments/1a...</td>\n",
       "      <td>Weed isn’t a personality. If your smoke circle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AskReddit</td>\n",
       "      <td>What is something that you believe every canna...</td>\n",
       "      <td>https://www.reddit.com/r/AskReddit/comments/1a...</td>\n",
       "      <td>I know folks who have smoked/ consumed for yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AskReddit</td>\n",
       "      <td>What is something that you believe every canna...</td>\n",
       "      <td>https://www.reddit.com/r/AskReddit/comments/1a...</td>\n",
       "      <td>Cross joints are not worth the structural effo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Subreddit                                         Post Title  \\\n",
       "11  AskReddit  What is something that you believe every canna...   \n",
       "12  AskReddit  What is something that you believe every canna...   \n",
       "13  AskReddit  What is something that you believe every canna...   \n",
       "14  AskReddit  What is something that you believe every canna...   \n",
       "15  AskReddit  What is something that you believe every canna...   \n",
       "16  AskReddit  What is something that you believe every canna...   \n",
       "17  AskReddit  What is something that you believe every canna...   \n",
       "18  AskReddit  What is something that you believe every canna...   \n",
       "19  AskReddit  What is something that you believe every canna...   \n",
       "\n",
       "                                             Post URL  \\\n",
       "11  https://www.reddit.com/r/AskReddit/comments/1a...   \n",
       "12  https://www.reddit.com/r/AskReddit/comments/1a...   \n",
       "13  https://www.reddit.com/r/AskReddit/comments/1a...   \n",
       "14  https://www.reddit.com/r/AskReddit/comments/1a...   \n",
       "15  https://www.reddit.com/r/AskReddit/comments/1a...   \n",
       "16  https://www.reddit.com/r/AskReddit/comments/1a...   \n",
       "17  https://www.reddit.com/r/AskReddit/comments/1a...   \n",
       "18  https://www.reddit.com/r/AskReddit/comments/1a...   \n",
       "19  https://www.reddit.com/r/AskReddit/comments/1a...   \n",
       "\n",
       "                                              Comment  \n",
       "11    It affects your memory, as well as your memory.  \n",
       "12  It’s not for everyone. Some people truly do ex...  \n",
       "13                                     Stay hydrated.  \n",
       "14  If you have an underlying mental health disord...  \n",
       "15  When deciding how many edibles…You can always ...  \n",
       "16  You smell like weed, you're just nose blind to...  \n",
       "17  Weed isn’t a personality. If your smoke circle...  \n",
       "18  I know folks who have smoked/ consumed for yea...  \n",
       "19  Cross joints are not worth the structural effo...  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You need to load from csv cuz u havent cleaned the emojis from df above.\n",
    "csv_file_path = 'reddit_data.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(csv_file_path, encoding='utf-16', sep='\\t')\n",
    "df[11:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "98321eaf-590a-43f3-87e2-1bf23ce216bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'People who have straight up rage quit a job, what was the final straw? 1. Many years ago while working in a manufacturing facility. My boss came into work already pissed off because his wife served him divorce papers. \\n\\nSaying “good morning” was apparently enough to set him off and he picked up a wrench from the table and threw it at my head. \\n\\nI ducked…it missed…then I just closed my toolbox and wheeled it to the truck lol 2. Not me, but a colleague once wrote a long stinker of an email, hit send at 10:30am and exited the building immediately. He blind-copied all receivers but sent it to multiple departments of a large multinational I was working at, no one knew who did/didn’t get the email, except for the gasps and OMGs around the office. He was completely disgruntled, and went in on multiple managers, supervisors and various colleagues with absolute venom. It was amazing, still the best work email I’ve ever received and some shit he called out actually had to be addressed by management, it brought about a lot of positive change. If you’re out there Khalil, that was awesome. 3. This was 20 years ago.\\n\\n\\nMy fiancé had been hospitalized for 16 months after a car accident.\\n\\nWhen she passed away my boss would not let me have time off for bereavement because we were not legally married. 4. I never have, but my favorite example was when a co-worker in student transportation, who had finally gotten a position she wanted after years of suffering through stress in another, was called by management over the summer and told she was being reassigned to the stressful position because no one else wanted to do it. She had fought too long and hard to get what she wanted, and her immediate response was, \"Then tell me what I need to do to resign.\" She did, and she\\'s been at peace with her decision ever since. 5. At one office job, I quit after the first day because the lady training me would ignore me when our manager wasn\\'t around, and I caught her snooping through my purse when I went to the bathroom.\\n\\nAt another job at a clinic, I quit after a month because they made me do a solo receptionist shift without training me on what I needed to do to open the clinic, and then I got yelled at for not knowing what to do. In front of patients. It was so bad, some of the patients came up to me after and asked if I was ok. 6. I was flat out lied to about the position. \\n\\nIt was a management position at a residential mental health facility and I had taken it (leaving a great paying but stressful position) because it wouldn\\'t require travel and was supposed to be much more laid back. On top of many other issues I ended up having to work eight weeks straight without a single day off (even weekends and one holiday) so after a very heated meeting with upper management where one person was flat out lying to cover their own butt, I sent a resignation email from the parking lot. 7. When I was driving home and my blood pressure shot through the roof cause somebody was driving the same make, model and color car as the boss.\\n\\n...obviously that wasn\\'t THE STRAW, just the recognition that there was to be no more straws. '"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concate all relevant text into 1 variable to output as mp3.\n",
    "def concatenate_q_and_all_comments(df, n_posts):\n",
    "    text_list = []  # Initialize as an empty list\n",
    "    current_list_index = -1  # Initialize a pointer to manage the current inner list\n",
    "    counter_to_read_outloud = 1\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        if index % n_posts == 0:\n",
    "            # Create a new string for each new range of indices (0-9, 10-19, ...)\n",
    "            text_list.append(\"\")  # Start with an empty string\n",
    "            current_list_index += 1  # Move to the next \"inner list\" which is actually a string now\n",
    "            counter_to_read_outloud = 1  # Reset counter for new group\n",
    "        # Concatenate 'Post Title' and 'Comment' if index is 0 or a multiple of 10\n",
    "        if index % n_posts == 0:\n",
    "            text_to_append = row['Post Title'] + \" \" + str(counter_to_read_outloud) + \". \" + row['Comment']\n",
    "        else:\n",
    "            # Use only 'Comment' otherwise\n",
    "            counter_to_read_outloud += 1\n",
    "            text_to_append = str(counter_to_read_outloud) + \". \" + row['Comment']\n",
    "        # Append the text to the current string, with a space for separation\n",
    "        text_list[current_list_index] += text_to_append + \" \"\n",
    "\n",
    "    return text_list\n",
    "\n",
    "reddit_list = concatenate_q_and_all_comments(df, 7)\n",
    "reddit_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4698b6ae-f7ed-4e1e-bbd9-93fed2adc477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ai_reading(text_to_use, index, char_limit, voice_id=\"pFZP5JQG7iQjIQuC4Bku\"):\n",
    "    # Max char limit of 100 characters\n",
    "    char_limit = min(char_limit, 100)\n",
    "    # Call ElevenLabs API to synthesize text\n",
    "    audio = elevenlabs.generate(text=text_to_use[index][:char_limit], voice=voice_id)\n",
    "    # Play the audio\n",
    "    elevenlabs.play(audio)\n",
    "    # with open('output.mp3', 'wb') as f:\n",
    "    #     for chunk in audio.iter_content(chunk_size=char_limit):\n",
    "    #         if chunk:\n",
    "    #             f.write(chunk)\n",
    "    # Save the audio\n",
    "    elevenlabs.save(audio,'audio.mp3')\n",
    "    # Print its been auto saved.\n",
    "    print(f\"MP3 file auto saved in: {os.getcwd()}\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "230c6809-3cff-4431-9cfc-c9ae9924b2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MP3 file auto saved in: C:\\Users\\kevin\\Google Drive\\My Drive\\Github\\Repos\\reddit_text_to_speech\n"
     ]
    }
   ],
   "source": [
    "# generate_ai_reading(reddit_list, 6, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c251d055-2a78-417c-bad8-92574dc52480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# elevenlabs.play(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "76c69836-6f9a-4e1f-8d31-dd64d5bf9cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# elevenlabs.save(audio,'audio.wav')\n",
    "# print(f\"WAV file saved: {download_directory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec537d9a-2b27-464e-955d-ee074083315d",
   "metadata": {},
   "source": [
    "# Download Gameplay Videos to use as cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "16c9e37c-2991-4d9e-b1eb-a512fc36aa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # v1: Download 1 video\n",
    "# import subprocess\n",
    "\n",
    "# # Command to download a video\n",
    "# command = ['yt-dlp', 'https://www.youtube.com/watch?v=YdoLTEZ1bI4']\n",
    "\n",
    "# # Running the command\n",
    "# subprocess.run(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "18910cff-fb07-4629-96dc-348976632a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # v2: Go to reddit and download gameplay videos\n",
    "# # Choose the subreddit\n",
    "# subreddit_name = \"gameplayvideos\"\n",
    "\n",
    "# # Access the subreddit\n",
    "# subreddit = reddit.subreddit(subreddit_name)\n",
    "\n",
    "# # Of last 24 hours only.\n",
    "# # top_posts = subreddit.top(time_filter='day', limit=10)\n",
    "# # Fetch the top 10 posts from all time\n",
    "# top_posts = subreddit.top(limit=10)\n",
    "\n",
    "# # Initialize an empty list to store the data\n",
    "# data = []\n",
    "\n",
    "# # Iterate over the posts and comments\n",
    "# for post in top_posts:\n",
    "#     post_title = post.title\n",
    "#     post_url = post.url\n",
    "#     subreddit_name = post.subreddit.display_name\n",
    "\n",
    "#     data.append([subreddit_name, post_title, post_url])\n",
    "#     # post.comment_sort = 'top'  # Sort comments by top votes\n",
    "#     # post.comments.replace_more(limit=0)  # Load all comments, remove 'more comments' links\n",
    "#     # top_comments = post.comments.list()[:10]  # Get top 10 comments\n",
    "\n",
    "#     # for comment in top_comments:\n",
    "#     #     # Append each comment along with post and subreddit details to the data list\n",
    "#     #     data.append([subreddit_name, post_title, post_url, comment.body])\n",
    "\n",
    "# # Create a DataFrame\n",
    "# df = pd.DataFrame(data, columns=['Subreddit', 'Post Title', 'Post URL'])\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a9a9b8d8-7dfa-4e78-b666-299fd8b9ad4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Directory where you want to save the downloaded videos\n",
    "# original_path = r'C:\\Users\\kevin\\Google Drive\\My Drive\\Github\\Repos\\reddit_text_to_speech\\gameplay_videos'\n",
    "# # Adding an extra '\\' to every '\\' found in the original path\n",
    "# escaped_path = original_path.replace(\"\\\\\", \"\\\\\\\\\")\n",
    "# download_directory = escaped_path\n",
    "# download_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6217187b-e408-4414-a893-ffc790f8c0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for url in df['Post URL']:\n",
    "#     command = [\n",
    "#         'yt-dlp',\n",
    "#         url,\n",
    "#         '-o', os.path.join(download_directory, '%(title)s.%(ext)s')\n",
    "#     ]\n",
    "#     try:\n",
    "#         subprocess.run(command, check=True)\n",
    "#     except subprocess.CalledProcessError as e:\n",
    "#         print(f\"Failed to download {url}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3665c10-fe70-4a3b-a020-b229221c69c6",
   "metadata": {},
   "source": [
    "# [WIP] Use Chatgpt API and Capcut API to generate video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735e6d17-30f2-4c8f-85e0-da04042a6858",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
